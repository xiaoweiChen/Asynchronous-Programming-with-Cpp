
现代 CPU 的计算速度非常快，当想要实现最大性能时，内存访问是主要瓶颈。内存访问的合理估计时间约为 150 纳秒。在此期间，我们的 3.6 GHz CPU 经历了 540 个时钟周期。粗略估计，如果 CPU 每两个周期执行一条指令，则有 270 条指令。对于普通应用程序，内存访问是一个问题，即使编译器可能会重新排序其生成的指令，并且 CPU 也可能重新排序指令以优化内存访问并尝试运行尽可能多的指令。

因此，为了提高现代 CPU 的性能，我们拥有的 CPU 缓存或内存缓存，即芯片中用于存储数据和指令的内存。这种内存比 RAM 快得多，允许 CPU 更快地检索数据，从而显著提高整体性能。

以实际中的缓存为例，想象一下厨师需要一些食材来为餐厅客户做午餐。现在，他们只在客户来到餐厅点餐时才购买这些食材，这会非常慢。他们也可以去超市购买一整天的食材，则可以在更短的时间内为所有客户做饭，并为他们提供餐点。

CPU 缓存遵循相同的概念：当 CPU 需要访问一个变量（比如一个 4 字节整数）时，会读取 64 个字节（此大小可能不同，具体取决于 CPU，但大多数现代 CPU 都使用该大小）的连续内存，以防需要访问更多连续的数据。

从内存访问的角度来看，线性内存数据结构（如 std::vector）的性能会更好，因为缓存可以大大提高性能。对于其他类型的数据结构（如 std::list），情况并非如此。

当然，这只是为了优化缓存的使用。

如果 CPU 内置缓存如此好，为什么所有内存不都是这样呢？答案是成本。缓存非常快（比 RAM 快得多），但也非常昂贵。

现代 CPU 采用分层缓存结构，通常由三个级别组成，分别称为 L1、 L2 和 L3：

\begin{itemize}
\item
L1 缓存最小、速度最快。它也是距离 CPU 最近的缓存，也是最昂贵的缓存。通常分为两部分：用于存储指令的指令缓存和用于存储数据的数据缓存。典型大小为 64 KB，分为 32 KB 用于存储指令和 32 KB 用于存储数据。 L1 缓存的通常访问时间为 1 到 3 纳秒。

\item
L2 缓存比 L1 缓存更大，速度也稍慢，但仍比 RAM 快得多。典型的 L2 缓存大小在 128Kb 到 512 Kb 之间（用于运行本章示例的 CPU 每个核芯有 512 Kb 的 L2 缓存）。 L2 缓存的通常访问时间约为 3 到 5 纳秒。

\item
L3 缓存是三者中最大且最慢的。 L1 和 L2 缓存是每个核芯的（每个核芯都有自己的 L1和 L2 缓存），但 L3 由多个核芯共享。我们的 CPU 有 32 Mb 的 L3 缓存，由每组八个核芯共享。通常的访问时间约为 10 到 15 纳秒。
\end{itemize}

接下来，让我们将注意力转向与内存缓存相关的另一个重要概念。

\mySubsubsection{13.4.1.}{缓存一致性}

CPU 不直接访问 RAM。这种访问始终通过缓存进行，并且只有当 CPU 在缓存中找不到所需数据时才会访问 RAM。在多核系统中，每个核芯都有自己的缓存，所以一块 RAM 可能同时存在于多个核芯的缓存中。这些副本需要始终保持同步；否则，计算结果可能不正确。

我们已经看到每个核芯都有自己的 L1 缓存。回到我们的例子，思考一下当使用非对齐内存运行该函数时会发生什么。

result\_data 的每个实例都是 8 个字节。我们创建一个包含 8 个 result\_data 实例的数组，每个线程一个。占用的总内存将为 64 个字节，所有实例在内存中都是连续的。每次线程更新随机数的总和时，都会更改存储在缓存中的值。记住， CPU 总是会一次读取和写入 64 个字节（称为缓存行 - 可以将其视为最小的内存访问单元）。所有变量都在同一个缓存行中，即使线程不共享它们（每个线程都有自己的变量 - sum）， CPU 也不知道这一点，需要让所有核芯都看到这些变化。

这里，有 8 个核芯，每个核芯都在运行一个线程。每个核芯都将 RAM 中的 64 字节内存加载到 L1 缓存中。由于线程只读取变量，所以一切正常。但是只要一个线程修改其变量，缓存行的内容就会失效。

现在，由于缓存行在其余 7 个核芯中无效， CPU 需要将更改传播到所有核芯，即使线程不共享变量，CPU 也不可能知道，它会更新所有核芯的所有缓存行以保持值一致。这称为缓存一致性。如果线程共享变量，则不将更改传播到所有核芯是不正确的。

我们的示例中，缓存一致性协议在 CPU 内部产生大量流量，所有线程都共享变量所在的内存区域，尽管从程序的角度来看并非如此。这就是称之为“伪共享”的原因：变量共享是因为缓存和缓存一致性协议的工作方式。

当将数据对齐到 64 字节边界时，每个实例占用 64 个字节。这保证了它们位于自己的缓存行中，并且不需要缓存一致性流量，这种情况下没有数据共享。在第二种情况下，性能要好得多。

使用 perf 来确认这确实发生了。

首先，在执行 sum\_random\_unaligned 时运行 perf。想要查看程序访问缓存的次数以及缓存未命中的次数。每次缓存需要更新，因为包含的数据也位于另一个核芯的缓存行中，这算作一次缓存未命中：

\begin{shell}
perf stat -e cache-references,cache-misses ./13x07-false_sharing
\end{shell}

\begin{shell}
Performance counter stats for './13x07-false_sharing':

     251,277,877     cache-references
     242,797,999     cache-misses
                     # 96.63% of all cache refs
\end{shell}

大多数缓存引用都是缓存未命中。由于伪分享，这是预期的。

现在，如果运行 sum\_random\_aligned，结果则会大不相同：

\begin{shell}
Performance counter stats for './13x07-false_sharing':

          851,506    cache-references
          231,703    cache-misses
                     # 27.21% of all cache refs
\end{shell}

缓存引用和缓存未命中的数量都少得多。这是因为无需不断更新所有核芯中的缓存来保持缓存一致性。

本节中，了解了多线程代码最常见的性能问题之一：伪共享。了解了有伪共享和没有伪共享的函数示例，以及伪共享对性能的负面影响。

下一节中，我回到第 5 章中实现的 SPSC 无锁队列并改进其性能。















